"""
Aplicaci√≥n Streamlit para el Generador Modular de Q&A
Interfaz principal para la generaci√≥n, visualizaci√≥n y exportaci√≥n de Q&A
"""

import asyncio
import os
import sys
from pathlib import Path
from typing import Dict, List, Any
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

# Agregar el directorio ra√≠z al path
sys.path.insert(0, str(Path(__file__).parent))

from config.settings import settings
from src.utils.logger import get_logger
from src.utils.data_models import QAItem, QABatch, GenerationRequest, ExportConfig
from src.generators.prompt_generator import PromptQAGenerator, generate_qa_from_prompt
from src.extractors.document_processor import DocumentQAProcessor, process_document_to_qa
from src.unifiers.data_unifier import QADataManager

# Configurar p√°gina
st.set_page_config(
    page_title="Generador Modular Q&A",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

logger = get_logger(__name__)

class QAGeneratorApp:
    """Clase principal de la aplicaci√≥n Streamlit"""
    
    def __init__(self):
        self.data_manager = QADataManager()
        self.prompt_generator = PromptQAGenerator()
        self.document_processor = DocumentQAProcessor()
        
        # Inicializar session state
        if "qa_data" not in st.session_state:
            st.session_state.qa_data = []
        if "current_batch" not in st.session_state:
            st.session_state.current_batch = None
        if "export_history" not in st.session_state:
            st.session_state.export_history = []
    
    def render_header(self):
        """Renderizar header principal"""
        st.title("ü§ñ Generador Modular de Q&A")
        st.markdown("**Genera preguntas y respuestas a partir de prompts tem√°ticos o documentos**")
        
        # Validar APIs
        api_status = settings.validate_api_keys()
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            status_icon = "‚úÖ" if api_status["openai"] else "‚ùå"
            st.metric("OpenAI", status_icon)
        with col2:
            status_icon = "‚úÖ" if api_status["anthropic"] else "‚ùå"
            st.metric("Anthropic", status_icon)
        with col3:
            status_icon = "‚úÖ" if api_status["google"] else "‚ùå"
            st.metric("Google", status_icon)
        with col4:
            status_icon = "‚úÖ" if api_status["perplexity"] else "‚ùå"
            st.metric("Perplexity", status_icon)
        
        st.divider()
    
    def render_sidebar(self):
        """Renderizar sidebar con configuraci√≥n"""
        with st.sidebar:
            st.header("‚öôÔ∏è Configuraci√≥n")
            
            # Configuraci√≥n de modelo
            st.subheader("Modelo de IA")
            available_providers = []
            api_status = settings.validate_api_keys()
            
            if api_status["openai"]:
                available_providers.append("openai")
            if api_status["anthropic"]:
                available_providers.append("anthropic")
            if api_status["google"]:
                available_providers.append("google")
            
            if not available_providers:
                st.error("‚ö†Ô∏è No hay APIs configuradas. Configura al menos una API key.")
                st.stop()
            
            modelo = st.selectbox(
                "Proveedor de IA",
                available_providers,
                index=0 if available_providers else None
            )
            
            # Configuraci√≥n de generaci√≥n
            st.subheader("Configuraci√≥n de Generaci√≥n")
            
            categoria = st.text_input("Categor√≠a", value="general")
            nivel = st.selectbox(
                "Nivel de dificultad",
                ["b√°sico", "intermedio", "avanzado"],
                index=1
            )
            idioma = st.selectbox(
                "Idioma",
                ["es", "en"],
                index=0
            )
            
            # Estad√≠sticas actuales
            if st.session_state.qa_data:
                st.subheader("üìä Datos Actuales")
                total_items = sum(len(batch.items) for batch in st.session_state.qa_data)
                st.metric("Total Q&A", total_items)
                st.metric("Batches", len(st.session_state.qa_data))
            
            return {
                "modelo": modelo,
                "categoria": categoria,
                "nivel": nivel,
                "idioma": idioma
            }
    
    def render_prompt_generator(self, config: Dict[str, Any]):
        """Renderizar secci√≥n de generaci√≥n por prompts"""
        st.header("üí≠ Generaci√≥n por Prompts Tem√°ticos")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            prompt_text = st.text_area(
                "Describe el tema para generar Q&A:",
                height=100,
                placeholder="Ej: Inteligencia artificial en medicina, Historia de Colombia, Programaci√≥n en Python..."
            )
        
        with col2:
            st.write("**Configuraci√≥n:**")
            num_preguntas = st.slider("N√∫mero de preguntas", 1, 50, 10)
            usar_busqueda = st.checkbox(
                "Usar b√∫squeda avanzada",
                help="Usa Perplexity para informaci√≥n actualizada"
            )
        
        if st.button("üöÄ Generar Q&A desde Prompt", type="primary", disabled=not prompt_text):
            with st.spinner("Generando Q&A..."):
                try:
                    # Crear request
                    request = GenerationRequest(
                        tipo="prompt",
                        prompt=prompt_text,
                        categoria=config["categoria"],
                        nivel=config["nivel"],
                        num_preguntas=num_preguntas,
                        modelo=config["modelo"],
                        idioma=config["idioma"],
                        usar_busqueda_avanzada=usar_busqueda
                    )
                    
                    # Generar Q&A (ejecutar funci√≥n async)
                    batch = asyncio.run(self.prompt_generator.generate_qa_batch(request))
                    
                    # Guardar en session state
                    st.session_state.qa_data.append(batch)
                    st.session_state.current_batch = batch
                    
                    st.success(f"‚úÖ Generadas {len(batch.items)} preguntas y respuestas!")
                    
                except Exception as e:
                    st.error(f"Error generando Q&A: {str(e)}")
                    logger.error(f"Error en generaci√≥n por prompt: {e}")
    
    def render_document_processor(self, config: Dict[str, Any]):
        """Renderizar secci√≥n de procesamiento de documentos"""
        st.header("üìÑ Procesamiento de Documentos")
        
        # Upload de archivo
        uploaded_file = st.file_uploader(
            "Sube tu documento",
            type=["pdf", "docx", "txt", "md"],
            help="Formatos soportados: PDF, DOCX, TXT, MD"
        )
        
        if uploaded_file:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write(f"**Archivo:** {uploaded_file.name}")
                st.write(f"**Tama√±o:** {uploaded_file.size / 1024:.1f} KB")
            
            with col2:
                st.write("**Configuraci√≥n:**")
                preguntas_por_chunk = st.slider("Preguntas por secci√≥n", 1, 10, 3)
                extraer_existente = st.checkbox(
                    "Extraer Q&A existentes",
                    value=True,
                    help="Buscar Q&A que ya est√©n en el documento"
                )
            
            if st.button("üìù Procesar Documento", type="primary"):
                with st.spinner("Procesando documento..."):
                    try:
                        # Guardar archivo temporalmente
                        temp_path = settings.DOCUMENTS_DIR / uploaded_file.name
                        with open(temp_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        
                        # Procesar documento
                        batch = asyncio.run(
                            self.document_processor.process_document(
                                str(temp_path),
                                categoria=config["categoria"],
                                nivel=config["nivel"],
                                preguntas_por_chunk=preguntas_por_chunk,
                                modelo=config["modelo"],
                                extraer_existente=extraer_existente
                            )
                        )
                        
                        # Limpiar archivo temporal
                        temp_path.unlink(missing_ok=True)
                        
                        # Guardar en session state
                        st.session_state.qa_data.append(batch)
                        st.session_state.current_batch = batch
                        
                        st.success(f"‚úÖ Procesado documento: {len(batch.items)} Q&A extra√≠dos!")
                        
                    except Exception as e:
                        st.error(f"Error procesando documento: {str(e)}")
                        logger.error(f"Error en procesamiento de documento: {e}")
    
    def render_qa_viewer(self):
        """Renderizar visualizador de Q&A"""
        if not st.session_state.qa_data:
            st.info("üëÜ Genera algunos Q&A usando las opciones de arriba para visualizarlos aqu√≠.")
            return
        
        st.header("üìã Visualizaci√≥n de Q&A Generados")
        
        # Tabs para diferentes vistas
        tab1, tab2, tab3 = st.tabs(["üîç Explorar", "üìä Estad√≠sticas", "‚öôÔ∏è Gesti√≥n"])
        
        with tab1:
            self.render_qa_explorer()
        
        with tab2:
            self.render_statistics()
        
        with tab3:
            self.render_data_management()
    
    def render_qa_explorer(self):
        """Renderizar explorador de Q&A"""
        # Combinar todos los items
        all_items = []
        for batch in st.session_state.qa_data:
            all_items.extend(batch.items)
        
        if not all_items:
            return
        
        # Filtros
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            categorias = list(set(item.categoria for item in all_items))
            categoria_filter = st.selectbox("Filtrar por categor√≠a", ["Todas"] + categorias)
        
        with col2:
            niveles = list(set(item.nivel for item in all_items))
            nivel_filter = st.selectbox("Filtrar por nivel", ["Todos"] + niveles)
        
        with col3:
            confianza_min = st.slider("Confianza m√≠nima", 0.0, 1.0, 0.0)
        
        with col4:
            busqueda = st.text_input("Buscar en preguntas/respuestas")
        
        # Aplicar filtros
        filtered_items = all_items.copy()
        
        if categoria_filter != "Todas":
            filtered_items = [item for item in filtered_items if item.categoria == categoria_filter]
        
        if nivel_filter != "Todos":
            filtered_items = [item for item in filtered_items if item.nivel == nivel_filter]
        
        filtered_items = [item for item in filtered_items if item.confianza >= confianza_min]
        
        if busqueda:
            busqueda_lower = busqueda.lower()
            filtered_items = [
                item for item in filtered_items 
                if busqueda_lower in item.pregunta.lower() or busqueda_lower in item.respuesta.lower()
            ]
        
        st.write(f"**Mostrando {len(filtered_items)} de {len(all_items)} elementos**")
        
        # Mostrar items
        for i, item in enumerate(filtered_items):
            with st.expander(f"Q{i+1}: {item.pregunta[:100]}{'...' if len(item.pregunta) > 100 else ''}"):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.markdown(f"**ü§î Pregunta:** {item.pregunta}")
                    st.markdown(f"**üí° Respuesta:** {item.respuesta}")
                
                with col2:
                    st.markdown(f"**üìÇ Categor√≠a:** {item.categoria}")
                    st.markdown(f"**üìà Nivel:** {item.nivel}")
                    st.markdown(f"**üéØ Confianza:** {item.confianza:.2f}")
                    st.markdown(f"**üóìÔ∏è Creado:** {item.fecha_creacion.strftime('%Y-%m-%d %H:%M')}")
                    
                    if item.fuentes:
                        st.markdown(f"**üìö Fuentes:** {', '.join(item.fuentes[:2])}{'...' if len(item.fuentes) > 2 else ''}")
    
    def render_statistics(self):
        """Renderizar estad√≠sticas"""
        # Combinar todos los items
        all_items = []
        for batch in st.session_state.qa_data:
            all_items.extend(batch.items)
        
        if not all_items:
            return
        
        # M√©tricas generales
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Q&A", len(all_items))
        with col2:
            st.metric("Batches", len(st.session_state.qa_data))
        with col3:
            avg_confidence = sum(item.confianza for item in all_items) / len(all_items)
            st.metric("Confianza Promedio", f"{avg_confidence:.2f}")
        with col4:
            categorias_unicas = len(set(item.categoria for item in all_items))
            st.metric("Categor√≠as √önicas", categorias_unicas)
        
        # Gr√°ficos
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribuci√≥n por categor√≠a
            categoria_counts = {}
            for item in all_items:
                categoria_counts[item.categoria] = categoria_counts.get(item.categoria, 0) + 1
            
            if categoria_counts:
                fig_cat = px.pie(
                    values=list(categoria_counts.values()),
                    names=list(categoria_counts.keys()),
                    title="Distribuci√≥n por Categor√≠a"
                )
                st.plotly_chart(fig_cat, use_container_width=True)
        
        with col2:
            # Distribuci√≥n por nivel
            nivel_counts = {}
            for item in all_items:
                nivel_counts[item.nivel] = nivel_counts.get(item.nivel, 0) + 1
            
            if nivel_counts:
                fig_nivel = px.bar(
                    x=list(nivel_counts.keys()),
                    y=list(nivel_counts.values()),
                    title="Distribuci√≥n por Nivel"
                )
                st.plotly_chart(fig_nivel, use_container_width=True)
        
        # Histograma de confianza
        confianzas = [item.confianza for item in all_items]
        fig_conf = px.histogram(
            x=confianzas,
            nbins=20,
            title="Distribuci√≥n de Niveles de Confianza"
        )
        st.plotly_chart(fig_conf, use_container_width=True)
    
    def render_data_management(self):
        """Renderizar gesti√≥n de datos"""
        st.subheader("üóÇÔ∏è Gesti√≥n de Datos")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Acciones de Datos:**")
            
            if st.button("üîÑ Fusionar Duplicados", help="Elimina elementos muy similares"):
                if st.session_state.qa_data:
                    # Agregar todos los batches al data manager
                    self.data_manager.unifier.batches = []
                    self.data_manager.unifier.unified_items = []
                    
                    for batch in st.session_state.qa_data:
                        self.data_manager.add_data(batch)
                    
                    # Fusionar duplicados
                    merged_count = self.data_manager.unifier.merge_similar_items()
                    st.success(f"Fusionados {merged_count} elementos duplicados")
            
            if st.button("üóëÔ∏è Limpiar Todo", type="secondary"):
                st.session_state.qa_data = []
                st.session_state.current_batch = None
                st.success("Datos limpiados")
                st.rerun()
        
        with col2:
            st.write("**Informaci√≥n de Batches:**")
            
            for i, batch in enumerate(st.session_state.qa_data):
                with st.expander(f"Batch {i+1} - {batch.origen} ({len(batch.items)} items)"):
                    st.json({
                        "ID": batch.id,
                        "Origen": batch.origen,
                        "Items": len(batch.items),
                        "Fecha": batch.fecha_creacion.strftime("%Y-%m-%d %H:%M:%S"),
                        "Estad√≠sticas": batch.get_stats()
                    })
    
    def render_export_section(self):
        """Renderizar secci√≥n de exportaci√≥n"""
        if not st.session_state.qa_data:
            st.info("No hay datos para exportar. Genera algunos Q&A primero.")
            return
        
        st.header("üíæ Exportaci√≥n de Datos")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Configuraci√≥n de exportaci√≥n
            formato = st.selectbox(
                "Formato de exportaci√≥n",
                ["csv", "json", "xlsx", "yaml"]
            )
            
            incluir_metadatos = st.checkbox("Incluir metadatos", value=True)
            
            nombre_archivo = st.text_input(
                "Nombre del archivo (opcional)",
                placeholder="qa_export_personalizado"
            )
        
        with col2:
            st.write("**Vista previa:**")
            total_items = sum(len(batch.items) for batch in st.session_state.qa_data)
            st.metric("Items a exportar", total_items)
            st.write(f"**Formato:** {formato.upper()}")
            st.write(f"**Incluir metadatos:** {'S√≠' if incluir_metadatos else 'No'}")
        
        if st.button("üì§ Exportar Datos", type="primary"):
            with st.spinner("Exportando datos..."):
                try:
                    # Preparar data manager
                    self.data_manager.unifier.batches = []
                    self.data_manager.unifier.unified_items = []
                    
                    for batch in st.session_state.qa_data:
                        self.data_manager.add_data(batch)
                    
                    # Configurar exportaci√≥n
                    export_config = ExportConfig(
                        formato=formato,
                        incluir_metadatos=incluir_metadatos,
                        nombre_archivo=nombre_archivo if nombre_archivo else None
                    )
                    
                    # Exportar
                    output_path = self.data_manager.process_and_export(export_config)
                    
                    # Guardar en historial
                    st.session_state.export_history.append({
                        "fecha": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "archivo": output_path,
                        "formato": formato,
                        "items": total_items
                    })
                    
                    st.success(f"‚úÖ Datos exportados exitosamente: `{output_path}`")
                    
                    # Mostrar bot√≥n de descarga si es posible
                    if os.path.exists(output_path):
                        with open(output_path, "rb") as file:
                            btn = st.download_button(
                                label="‚¨áÔ∏è Descargar archivo",
                                data=file.read(),
                                file_name=os.path.basename(output_path),
                                mime="application/octet-stream"
                            )
                    
                except Exception as e:
                    st.error(f"Error exportando datos: {str(e)}")
                    logger.error(f"Error en exportaci√≥n: {e}")
        
        # Historial de exportaciones
        if st.session_state.export_history:
            st.subheader("üìã Historial de Exportaciones")
            df_history = pd.DataFrame(st.session_state.export_history)
            st.dataframe(df_history, use_container_width=True)
    
    def run(self):
        """Ejecutar la aplicaci√≥n principal"""
        self.render_header()
        config = self.render_sidebar()
        
        # Pesta√±as principales
        tab1, tab2, tab3, tab4 = st.tabs([
            "üí≠ Generar por Prompt",
            "üìÑ Procesar Documentos", 
            "üìã Ver Q&A",
            "üíæ Exportar"
        ])
        
        with tab1:
            self.render_prompt_generator(config)
        
        with tab2:
            self.render_document_processor(config)
        
        with tab3:
            self.render_qa_viewer()
        
        with tab4:
            self.render_export_section()

# Ejecutar aplicaci√≥n
if __name__ == "__main__":
    app = QAGeneratorApp()
    app.run()